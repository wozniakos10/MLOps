{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501b5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Integer, String\n",
    "from typing import List, Optional\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import Session\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import select\n",
    "from datasets import load_dataset\n",
    "from sqlalchemy import Float, Boolean\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from pymilvus import MilvusClient\n",
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "# download data\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "import fitz\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3010fd0",
   "metadata": {},
   "source": [
    "## DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d214486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = URL.create(\n",
    "    drivername=\"postgresql+psycopg\",\n",
    "    username=\"postgres\",\n",
    "    password=\"password\",\n",
    "    host=\"localhost\",\n",
    "    port=5555,\n",
    "    database=\"similarity_search_service_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcaa01",
   "metadata": {},
   "source": [
    "## Base class for table definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9316f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base class for the table definition\n",
    "class Base(DeclarativeBase):\n",
    "    __abstract__ = True\n",
    "\n",
    "\n",
    "# Create the table definition\n",
    "class Images(Base):\n",
    "    __tablename__ = \"images\"\n",
    "    VECTOR_LENGTH = 512\n",
    "\n",
    "    # primary key\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    # image path - we will use it to store the path to the image file, after similarity search we can use it to retrieve the image and display it\n",
    "    image_path: Mapped[str] = mapped_column(String(256))\n",
    "    # image embedding - we will store the image embedding in this column, the image embedding is a list of 512 floats this is the output of the sentence transformer model\n",
    "    image_embedding: Mapped[List[float]] = mapped_column(Vector(VECTOR_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be55eb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the database and creating the table\n",
    "engine = create_engine(db_url)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2651d8e1",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621998e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable function to insert data into the table\n",
    "def insert_image(\n",
    "    engine: sqlalchemy.Engine, image_path: str, image_embedding: list[float]\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        # create the image object\n",
    "        image = Images(image_path=image_path, image_embedding=image_embedding)\n",
    "        # add the image object to the session\n",
    "        session.add(image)\n",
    "        # commit the transaction\n",
    "        session.commit()\n",
    "\n",
    "\n",
    "# calculate the cosine similarity between the first image and the K rest of the images, order the images by the similarity score\n",
    "def find_k_images(\n",
    "    engine: sqlalchemy.Engine, k: int, orginal_image: Images\n",
    ") -> list[Images]:\n",
    "    with Session(engine) as session:\n",
    "        # execution_options={\"prebuffer_rows\": True} is used to prebuffer the rows, this is useful when we want to fetch the rows in chunks and return them after session is closed\n",
    "        result = session.execute(\n",
    "            select(Images)\n",
    "            .order_by(\n",
    "                Images.image_embedding.cosine_distance(orginal_image.image_embedding)\n",
    "            )\n",
    "            .limit(k),\n",
    "            execution_options={\"prebuffer_rows\": True},\n",
    "        )\n",
    "        return result\n",
    "\n",
    "\n",
    "# find the images with the similarity score greater than 0.9\n",
    "def find_images_with_similarity_score_greater_than(\n",
    "    engine: sqlalchemy.Engine, similarity_score: float, orginal_image: Images\n",
    ") -> list[Images]:\n",
    "    with Session(engine) as session:\n",
    "        result = session.execute(\n",
    "            select(Images).filter(\n",
    "                Images.image_embedding.cosine_distance(orginal_image.image_embedding)\n",
    "                > similarity_score\n",
    "            ),\n",
    "            execution_options={\"prebuffer_rows\": True},\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68539a4a",
   "metadata": {},
   "source": [
    "## Insert random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22be14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert some data into the table\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    image_path = f\"image_{i}.jpg\"\n",
    "    image_embedding = np.random.rand(512).tolist()\n",
    "    insert_image(engine, image_path, image_embedding)\n",
    "\n",
    "# select first image from the table\n",
    "with Session(engine) as session:\n",
    "    image = session.query(Images).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "864b9353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_0.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the 10 most similar images to the first image\n",
    "k = 10\n",
    "similar_images = find_k_images(engine, k, image)\n",
    "x = similar_images.fetchall()\n",
    "# Extracting image paths from the result\n",
    "img = x[0][0]\n",
    "img.image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37075c",
   "metadata": {},
   "source": [
    "## Download Steam Game dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6629cc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppID': Value('int64'), 'Name': Value('string'), 'Release date': Value('string'), 'Estimated owners': Value('string'), 'Peak CCU': Value('int64'), 'Required age': Value('int64'), 'Price': Value('float64'), 'DLC count': Value('int64'), 'About the game': Value('string'), 'Supported languages': Value('string'), 'Full audio languages': Value('string'), 'Reviews': Value('string'), 'Header image': Value('string'), 'Website': Value('string'), 'Support url': Value('string'), 'Support email': Value('string'), 'Windows': Value('bool'), 'Mac': Value('bool'), 'Linux': Value('bool'), 'Metacritic score': Value('int64'), 'Metacritic url': Value('string'), 'User score': Value('int64'), 'Positive': Value('int64'), 'Negative': Value('int64'), 'Score rank': Value('float64'), 'Achievements': Value('int64'), 'Recommendations': Value('int64'), 'Notes': Value('string'), 'Average playtime forever': Value('int64'), 'Average playtime two weeks': Value('int64'), 'Median playtime forever': Value('int64'), 'Median playtime two weeks': Value('int64'), 'Developers': Value('string'), 'Publishers': Value('string'), 'Categories': Value('string'), 'Genres': Value('string'), 'Tags': Value('string'), 'Screenshots': Value('string'), 'Movies': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"FronkonGames/steam-games-dataset\")\n",
    "\n",
    "# get columns names and types\n",
    "columns = dataset[\"train\"].features\n",
    "print(columns)\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Name\",\n",
    "    \"Windows\",\n",
    "    \"Linux\",\n",
    "    \"Mac\",\n",
    "    \"About the game\",\n",
    "    \"Supported languages\",\n",
    "    \"Price\",\n",
    "]\n",
    "\n",
    "N = 40000\n",
    "dataset = dataset[\"train\"].select_columns(columns_to_keep).select(range(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0786c",
   "metadata": {},
   "source": [
    "## Game table definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6313b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Games(Base):\n",
    "    __tablename__ = \"games\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    # the vector size produced by the model taken from documentation https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n",
    "    VECTOR_LENGTH = 512\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String(256))\n",
    "    description: Mapped[str] = mapped_column(String(4096))\n",
    "    windows: Mapped[bool] = mapped_column(Boolean)\n",
    "    linux: Mapped[bool] = mapped_column(Boolean)\n",
    "    mac: Mapped[bool] = mapped_column(Boolean)\n",
    "    price: Mapped[float] = mapped_column(Float)\n",
    "    game_description_embedding: Mapped[List[float]] = mapped_column(\n",
    "        Vector(VECTOR_LENGTH)\n",
    "    )\n",
    "\n",
    "\n",
    "# Dropping and creating the table again\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23ac028",
   "metadata": {},
   "source": [
    "## Getting embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ba4534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distiluse-base-multilingual-cased-v2\"\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "model = SentenceTransformer(checkpoint, device=device)\n",
    "\n",
    "\n",
    "def generate_embeddings(text: str) -> list[float]:\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c33c1",
   "metadata": {},
   "source": [
    "## Insert games data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b612969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_games(engine, dataset):\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for i, game in enumerate(dataset):\n",
    "            game_description = game[\"About the game\"] or \"\"\n",
    "            game_embedding = generate_embeddings(game_description)\n",
    "            name, windows, linux, mac, price = (\n",
    "                game[\"Name\"],\n",
    "                game[\"Windows\"],\n",
    "                game[\"Linux\"],\n",
    "                game[\"Mac\"],\n",
    "                game[\"Price\"],\n",
    "            )\n",
    "            if name and windows and linux and mac and price and game_description:\n",
    "                game = Games(\n",
    "                    name=game[\"Name\"],\n",
    "                    description=game_description[0:4096],\n",
    "                    windows=game[\"Windows\"],\n",
    "                    linux=game[\"Linux\"],\n",
    "                    mac=game[\"Mac\"],\n",
    "                    price=game[\"Price\"],\n",
    "                    game_description_embedding=game_embedding,\n",
    "                )\n",
    "                with Session(engine) as session:\n",
    "                    session.add(game)\n",
    "                    session.commit()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9d1761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40000/40000 [10:43<00:00, 62.15it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_games(engine, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71ff4160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_game(\n",
    "    engine: sqlalchemy.Engine,\n",
    "    game_description: str,\n",
    "    windows: Optional[bool] = None,\n",
    "    linux: Optional[bool] = None,\n",
    "    mac: Optional[bool] = None,\n",
    "    price: Optional[int] = None,\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        game_embedding = generate_embeddings(game_description)\n",
    "\n",
    "        query = select(Games).order_by(\n",
    "            Games.game_description_embedding.cosine_distance(game_embedding)\n",
    "        )\n",
    "\n",
    "        if price:\n",
    "            query = query.filter(Games.price <= price)\n",
    "        if windows:\n",
    "            query = query.filter(Games.windows == True)\n",
    "        if linux:\n",
    "            query = query.filter(Games.linux == True)\n",
    "        if mac:\n",
    "            query = query.filter(Games.mac == True)\n",
    "\n",
    "        result = session.execute(query, execution_options={\"prebuffer_rows\": True})\n",
    "        game = result.scalars().first()\n",
    "\n",
    "        return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bd9a0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Ultimate Spider Hero\n",
      "Description: Ultimate Spider Hero game was designed for real heroes! Your mission is to help poor residents of the Metropolis and to save them from the terrible monsters. Move forward to fight your enemies and try not to fall! Features: Simple and addictive gameplay Nice graphics Awesome Ultimate Spider Hero Countless Steam achievements for you to collect! Compatibility with multiple major platforms (Windows, Mac, Linux, SteamOS) Make your way through the endless labyrinths of long, confusing city streets together with your favorite hero from countless movies and cartoons! Although this may look simple enough, things are not as easy as they seem. You will have to learn how to cling into houses properly using your web, otherwise you will fall to your demise. If you manage to do so - you will become a real superhero, armed with elusiveness, agility and speed and the ability to tirelessly swing across the rooftops and between the huge skyscrapers this urban landscape has to offer in this thrilling game of a super spider. It's fun, the visuals are magnificent and the controls are simple!\n",
      "Game: 3D PUZZLE - Modern House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game_1 = find_game(engine, \"This is a game about a hero who saves the world\", price=10)\n",
    "print(f\"Game: {game_1.name}\")\n",
    "print(f\"Description: {game_1.description}\")\n",
    "\n",
    "game_2 = find_game(engine, game_description=\"Home decorating\", price=20)\n",
    "print(f\"Game: {game_2.name}\")\n",
    "print(f\"Description: {game_2.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "283ccebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 3D PUZZLE - Old House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game_3 = find_game(engine, game_description=\"Home decorating\", mac=True, price=5)\n",
    "print(f\"Game: {game_3.name}\")\n",
    "print(f\"Description: {game_3.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b62b8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the begining I thought that it returns the same object\n",
    "# But I see that descriptions are the same but names are different and\n",
    "# that happens because of filtering\n",
    "game_2.name == game_3.name, game_2.description == game_3.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e9174ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 571)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(game_2.description), len(game_3.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3dcba92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Viki Spotter: Sports\n",
      "Description: This game is great for developing your mindfulness skills. Here you have to take a good look at the pictures offered to you and find out how they differ among themselves. Whether you are an adult or a child - this may not be so easy at all, some differences are very difficult to locate for the first time. In this part of the game you have to go straight to the gym. Features: Many interesting scenes Pleasant graphics Easy gameplay Many Steam achievements The game is suitable for Windows, Mac and Linux If you suddenly forgot what the gym looks like or what kinds of sports exist around - it's time to remember this together with the little girl named Viki. She is going to implement a fascinating journey into the world of big sport and learn about all that might seem interesting. And in helping her will be specifically you. Visit various competitions and simulators, learn all about the world of sports and entertain yourself by finding differences in a variety of colorful pictures. Spend time with benefit and interest. The game perfectly trains such skills as resourcefulness and attentiveness. And if the tasks in the game seem too complicated for you, you can always use the hint. But remember that at the same time all sports interest is lost!\n",
      "Game: Soccerlypse\n",
      "Description: Soccerlypse is an FPS soccer game (First Person Shooter) where the main objective is to get the ball in the goal more than the opposition and win the game. Play Soccerlypse against real players across the world as you kick, shoot, or explode the ball over the line. FEATURES: - FPS Soccer - Pistols - Machine Guns - Shotguns - Rocket Launchers - Soccer Balls - Real Multiplayer! HOW IT WORKS: - In this FPS soccer game, the matches last 5 minutes, and up to 8 players can play at once in a 4 v 4 battle. - Your total goals, kills, matches and wins leaderboards are only updated if you are still in the match as it finishes. - Goals scored when you are alone in a room generally do not count towards the leaderboard total, although if the last opponent leaves the match, you will still be able to score the next goal, to prevent people leaving rooms to stop a goal from counting. - You can make a room private, so that only people who know the name of it can enter with you. - You can join a match at anytime up until it ends. - Everybody starts with a pistol, but pickups are available in the match. - You can also unlock secondary weapons to start the match with, after playing a certain number of matches. - You can click the 'Offer Rematch?' button after a match has finished to automatically join a new room with the same name, along with others who also clicked the button. - Optionally, you can play against an AI bot player instead. Grab some mates with you and have a go at FPS soccer in Soccerlypse! Great party fun :)\n",
      "Game: Pixel Traffic: Circle Rush\n",
      "Description: Finally on Steam, this long-awaited game has finally been released! This game will help anyone overcome boredom, filling their time with fun, and interest! Features: Simple and easy controls Amazing graphics Tons of game difficulties to choose from A wide variety of different cars Lots of amazing achievements You, the driver, have to sit behind the wheel of a car, and show care and caution, to avoid collision with a circle of moving cars, who, of course, do not observe traffic rules. You must carefully calculate the timing, otherwise a collision is inevitable! The game is harder than it seems at first glance, and after a couple of minutes, you will feel how difficult it will be to squeeze between the two cars moving at different speeds. Their number will increase, and the complexity will increase for each successful lap. But your efforts will be well rewarded! For each successful lap you get a gold coin, which can then be spent on a lots of new, unique vehicles. Additionally, your achievements will be carefully counted, and you will have the opportunity to compete with your friends, and see who will be the best in this awesome, hard game!\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, game_description=\"Sport game\", price=25)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")\n",
    "\n",
    "game = find_game(engine, game_description=\"Football game\", price=25)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")\n",
    "\n",
    "game = find_game(engine, game_description=\"Sport car game\", price=25)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e37ec0",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dff09add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Milvus Client setup\n",
    "host = \"localhost\"\n",
    "port = \"19530\"\n",
    "\n",
    "milvus_client = MilvusClient(host=host, port=port)\n",
    "\n",
    "# loading env var\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b0df330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Milvus Collection Schema definition\n",
    "VECTOR_LENGTH = 768  # check the dimensionality for Silver Retriever Base (v1.1) model\n",
    "\n",
    "id_field = FieldSchema(\n",
    "    name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"Primary id\"\n",
    ")\n",
    "text = FieldSchema(\n",
    "    name=\"text\", dtype=DataType.VARCHAR, max_length=4096, description=\"Page text\"\n",
    ")\n",
    "embedding_text = FieldSchema(\n",
    "    \"embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=VECTOR_LENGTH,\n",
    "    description=\"Embedded text\",\n",
    ")\n",
    "\n",
    "fields = [id_field, text, embedding_text]\n",
    "\n",
    "schema = CollectionSchema(\n",
    "    fields=fields,\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    description=\"RAG Texts collection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18478461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_texts_and_embeddings']\n",
      "{'collection_name': 'rag_texts_and_embeddings', 'auto_id': True, 'num_shards': 1, 'description': 'RAG Texts collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': 'Primary id', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'text', 'description': 'Page text', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 102, 'name': 'embedding', 'description': 'Embedded text', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 461834675364823240, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': True, 'created_timestamp': 461834685582147588}\n"
     ]
    }
   ],
   "source": [
    "# Create Milvus Collection and index\n",
    "COLLECTION_NAME = \"rag_texts_and_embeddings\"\n",
    "\n",
    "milvus_client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64},  # lower values for speed\n",
    ")\n",
    "\n",
    "milvus_client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec86c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data source and destination\n",
    "## the document origin destination from which document will be downloaded\n",
    "pdf_url = \"https://www.iab.org.pl/wp-content/uploads/2024/04/Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the document\n",
    "file_name = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the processed document\n",
    "file_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.json\"\n",
    "\n",
    "## local destination of the embedded pages of the document\n",
    "embeddings_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska-Embeddings.json\"\n",
    "\n",
    "## local destination of all above local required files\n",
    "data_dir = \"./lab_data\"\n",
    "# Creating data directory if it does not exist\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8833189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from the given URL\n",
    "def download_pdf_data(pdf_url: str, file_name: str) -> None:\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    with open(os.path.join(data_dir, file_name), \"wb\") as file:\n",
    "        for block in response.iter_content(chunk_size=1024):\n",
    "            if block:\n",
    "                file.write(block)\n",
    "\n",
    "\n",
    "download_pdf_data(pdf_url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a646bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF and save it as JSON\n",
    "def extract_pdf_text(file_name, file_json):\n",
    "    document = fitz.open(os.path.join(data_dir, file_name))\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        pages.append({\"page_num\": page_num, \"text\": page_text})\n",
    "\n",
    "    with open(os.path.join(data_dir, file_json), \"w\") as file:\n",
    "        json.dump(pages, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "extract_pdf_text(file_name, file_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2ea71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 7d121b9a-fe07-4844-8a0e-33b993fd1449)')' thrown while requesting HEAD https://huggingface.co/ipipan/silver-retriever-base-v1.1/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the extracted text and save them as JSON\n",
    "def generate_embeddings_milvus(file_json, embeddings_json, model):\n",
    "    pages = []\n",
    "    with open(os.path.join(data_dir, file_json), \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for page in data:\n",
    "        pages.append(page[\"text\"])\n",
    "\n",
    "    embeddings = model.encode(pages)\n",
    "\n",
    "    embeddings_paginated = []\n",
    "    for page_num in range(len(embeddings)):\n",
    "        embeddings_paginated.append(\n",
    "            {\"page_num\": page_num, \"embedding\": embeddings[page_num].tolist()}\n",
    "        )\n",
    "\n",
    "    with open(os.path.join(data_dir, embeddings_json), \"w\") as file:\n",
    "        json.dump(embeddings_paginated, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "model_name = \"ipipan/silver-retriever-base-v1.1\"\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "milvius_embedding_model = SentenceTransformer(model_name, device=device)\n",
    "generate_embeddings_milvus(file_json, embeddings_json, milvius_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eef721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert embeddings into Milvus collection\n",
    "def insert_embeddings(file_json, embeddings_json, client=milvus_client):\n",
    "    rows = []\n",
    "    with (\n",
    "        open(os.path.join(data_dir, file_json), \"r\") as t_f,\n",
    "        open(os.path.join(data_dir, embeddings_json), \"r\") as e_f,\n",
    "    ):\n",
    "        text_data, embedding_data = json.load(t_f), json.load(e_f)\n",
    "        text_data = list(map(lambda d: d[\"text\"], text_data))\n",
    "        embedding_data = list(map(lambda d: d[\"embedding\"], embedding_data))\n",
    "\n",
    "        for page, (text, embedding) in enumerate(zip(text_data, embedding_data)):\n",
    "            rows.append({\"text\": text, \"embedding\": embedding})\n",
    "\n",
    "    client.insert(collection_name=\"rag_texts_and_embeddings\", data=rows)\n",
    "\n",
    "\n",
    "insert_embeddings(file_json, embeddings_json, client=milvus_client)\n",
    "\n",
    "# load inserted data into memory\n",
    "milvus_client.load_collection(\"rag_texts_and_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "992dc3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 461834675364823495, 'distance': 29.12518882751465, 'entity': {'text': 'Historia powstania\\nsztucznej inteligencji\\n7\\nW języku potocznym „sztuczny\" oznacza to, co\\njest \\nwytworem \\nmającym \\nnaśladować \\ncoś\\nnaturalnego. W takim znaczeniu używamy\\nterminu ,,sztuczny\\'\\', gdy mówimy o sztucznym\\nlodowisku lub oku. Sztuczna inteligencja byłaby\\nczymś (programem, maszyną) symulującym\\ninteligencję naturalną, ludzką.\\nSztuczna inteligencja (AI) to obszar informatyki,\\nktóry skupia się na tworzeniu programów\\nkomputerowych zdolnych do wykonywania\\nzadań, które wymagają ludzkiej inteligencji. \\nTe zadania obejmują rozpoznawanie wzorców,\\nrozumienie języka naturalnego, podejmowanie\\ndecyzji, uczenie się, planowanie i wiele innych.\\nGłównym celem AI jest stworzenie systemów,\\nktóre są zdolne do myślenia i podejmowania\\ndecyzji na sposób przypominający ludzki.\\nHistoria sztucznej inteligencji sięga lat 50. \\nXX wieku, kiedy to powstały pierwsze koncepcje\\ni modele tego, co mogłoby stać się sztuczną\\ninteligencją. Jednym z pionierów był Alan\\nTuring, który sformułował test Turinga, mający\\nna \\ncelu \\nocenę \\nzdolności \\nmaszyny \\ndo\\ninteligentnego \\nzachowania \\nna \\npoziomie\\nludzkim. Jednakże dopiero w latach 80. i 90.\\nnastąpił \\nprawdziwy \\nprzełom \\nw \\ndziedzinie\\nsztucznej \\ninteligencji \\ndzięki \\npostępowi \\nw\\ndziedzinie algorytmów uczenia maszynowego.\\nW wypadku sztucznej inteligencji mamy na\\nuwadze system, który realizowałby niektóre\\nfunkcje \\numysłu \\n– \\nczasami \\nw \\nsposób\\nprzewyższający funkcje naturalne (na przykład,\\naby był wolny od pomyłek przy liczeniu oraz\\ndefektów \\npamięci). \\nInteligencja \\njest \\nwła-\\nściwością umysłu. \\nSkłada się na nią szereg umiejętności, takich jak\\nzdolność do komunikowania, rozwiązywania\\nproblemów, uczenia się i dostosowywania do\\nsytuacji. \\nIstotna \\njest \\njednak \\numiejętność\\nrozumowania.\\nWspółczesne systemy sztucznej inteligencji są\\ninteligentne tylko w ograniczonym obszarze. \\nNa przykład komputer potrafi grać w szachy w\\ntaki \\nsposób, \\nże \\nwygrywa \\nz \\nszachowym\\narcymistrzem. W 1996 r. Deep Blue wygrał jedną\\npartię \\nszachów \\nz \\nGarry \\nKasparowem,\\nprzegrywając cały mecz wynikiem 4:2 (przy\\ndwóch remisach).\\nPóźniej Deep Blue został ulepszony i nie-\\noficjalnie \\nnazwany \\n„Deeper \\nBlue\". \\nZagrał\\nponownie z Kasparowem w maju 1997 roku.\\nMecz \\nskończył \\nsię \\nwynikiem \\n3½:2½ \\ndla\\nkomputera. W ten sposób Deep Blue stał się\\npierwszym systemem komputerowym, który\\nwygrał z aktualnym mistrzem świata w meczu\\nze standardową kontrolą czasu.\\nŹródło: Midjourney – obraz wygenerowany przez AI\\n'}}, {'id': 461834675364823498, 'distance': 30.7041072845459, 'entity': {'text': 'Rodzaje sztucznej\\ninteligencji\\n1 0\\nGłówne rodzaje AI\\nSztuczna inteligencja (AI) obejmuje różne\\nrodzaje, z których każdy ma specyficzne\\ncechy i zastosowania. Oto kilka głównych\\nrodzajów sztucznej inteligencji:\\n Sztuczna inteligencja słaba (wąska): \\nJest to rodzaj AI, która jest zaprojektowana do\\nwykonywania \\nkonkretnego \\nzadania \\nlub\\nograniczonej kategorii zadań bez zdolności\\nogólnego rozumienia. Na przykład: systemy do\\nrozpoznawania mowy, rozpoznawania obrazów,\\nczy gier planszowych.\\nSztuczna inteligencja silna: \\nW przeciwieństwie do sztucznej inteligencji\\nsłabej, ta kategoria obejmuje systemy zdolne do\\nogólnego zrozumienia i radzenia sobie z róż-\\nnymi zadaniami na poziomie porównywalnym\\ndo ludzkiej inteligencji. Sztuczna inteligencja\\nsilna \\nposiada \\nzdolność \\ndo \\nuczenia \\nsię,\\nrozumienia kontekstu i dostosowywania się do\\nróżnych sytuacji.\\nSztuczna inteligencja umysłowa: \\nTen rodzaj sztucznej inteligencji ma na celu\\nemulowanie ludzkiego myślenia i zrozumienia\\nw najbardziej zaawansowany sposób. Obejmuje\\nto zdolność do samodzielnego uczenia się,\\nprzetwarzania języka naturalnego, rozumienia\\nkontekstu i nawet posiadania świadomości.\\nSztuczna inteligencja zwiększająca \\n(Augmented Intelligence): \\nInaczej nazywana \"inteligencją wspomaganą\",\\nto podejście, które łączy siły ludzkiej inteligencji\\nz możliwościami sztucznej inteligencji w celu\\nwzmacniania i ułatwiania ludzkich działań.\\nCelem \\njest \\nstworzenie \\nsynergii \\nmiędzy\\nzdolnościami maszyn a ludzkim myśleniem.\\nSztuczna inteligencja bezpieczna (Safe AI): \\nSkupia się na opracowywaniu i wdrażaniu\\nśrodków mających na celu minimalizację ryzyka\\nzwiązanego \\nz \\nrozwijającą \\nsię \\nsztuczną\\ninteligencją, \\nzapobieganie \\nniepożądanym\\nskutkom i zachowaniu zgodności z wartościami\\netycznymi.\\nSztuczna inteligencja odwrócona \\n(Inverse AI): \\nPolega na modelowaniu procesów myślowych\\nludzi w celu lepszego zrozumienia i dosto-\\nsowywania \\ninterakcji \\nmaszyn \\ndo \\nludzkich\\noczekiwań.\\nSztuczna inteligencja reprezentacyjna\\n(Representational AI): \\nKoncentruje \\nsię \\nna \\ntworzeniu \\nmodeli\\nreprezentujących wiedzę o świecie w sposób,\\nktóry umożliwia skuteczne rozumienie i prze-\\ntwarzanie informacji.\\nSztuczna inteligencja predykcyjna\\n(Predictive AI):\\nKoncentruje się na przewidywaniu wyników na\\npodstawie \\ndostępnych \\ndanych. \\nPrzykłady\\nobejmują modele prognozujące pogodę, wyniki\\nwyborów czy ceny akcji.\\nŹródło: Canva\\n'}}, {'id': 461834675364823504, 'distance': 34.27998733520508, 'entity': {'text': 'Inne modele sztucznej\\ninteligencji\\n1 6\\nGeneratywne modele grafiki\\nkomputerowej:\\nPix2Pix: Ten model jest wykorzystywany do\\nkonwersji obrazów z jednej dziedziny na obrazy\\nw innej. Na przykład może przekształcać obrazy\\nczarnobiałe na kolorowe, rysunki w realistyczne\\nobrazy, itp.\\nSztuczna \\ninteligencja \\ngeneratywna \\nma\\npotencjał zastosowania w wielu dziedzinach,\\ntakich jak: sztuka, projektowanie, produkcja\\ntreści multimedialnych, czy nawet medycyna.\\nJednakże, \\nrównocześnie \\nz \\nzastosowaniami\\npozytywnymi, pojawiają się także wyzwania\\nzwiązane z etyką i bezpieczeństwem, zwłaszcza\\nw \\nkontekście \\nfałszywych \\ninformacji \\ni\\ndeepfake\\'ów.\\nSztuczna inteligencja dedukcyjna:\\nSkoncentrowana na wykorzystywaniu reguł\\nlogicznych \\ndo \\nwyciągania \\nwniosków \\ni\\npodejmowania decyzji. Ten rodzaj AI działa na\\npodstawie dostarczonych danych i reguł, nie\\nwymaga eksploracyjnego uczenia się.\\nSztuczna inteligencja indukcyjna: \\nOparta na zdolności do wyciągania ogólnych\\nzasad lub wniosków na podstawie konkretnych\\nprzykładów. Indukcyjna sztuczna inteligencja\\nma \\nzdolność \\nuczenia \\nsię \\nna \\npodstawie\\ndoświadczeń i dostarczonych danych.\\nSztuczna \\ninteligencja \\nuczenia\\nmaszynowego (Machine Learning - ML): \\nTo \\nobszar \\nAI, \\nktóry \\numożliwia \\nsystemom\\nkomputerowym naukę bez bezpośredniego\\nprogramowania. \\nAlgorytmy \\nuczenia\\nmaszynowego \\npozwalają \\nmaszynom\\nsamodzielnie dostosowywać się do nowych\\ndanych i poprawiać swoje działania w czasie.\\nSztuczna inteligencja uczenia głębokiego\\n(Deep Learning): \\nJest to rodzaj uczenia maszynowego, w którym\\nmodele (zwane sieciami neuronowymi) składają\\nsię z wielu warstw (stąd \"głębokie\") i są w stanie\\nprzetwarzać złożone dane, takie jak obrazy czy\\ndźwięki.\\nSztuczna inteligencja ewolucyjna: \\nInspirując się procesami ewolucji biologicznej,\\nsztuczna inteligencja ewolucyjna wykorzystuje\\nalgorytmy \\ngenetyczne \\ndo \\newoluowania\\nprogramów \\nkomputerowych \\nw \\nkierunku\\nrozwiązania konkretnego problemu.\\nSztuczna inteligencja probabilistyczna:\\nObejmuje \\nmodelowanie \\nniepewności \\ni\\nprawdopodobieństw w procesie podejmowania\\ndecyzji. \\nWykorzystuje \\nrachunek\\nprawdopodobieństwa \\nw \\nanalizie \\ndanych \\ni\\nprzewidywaniu wyników.\\nSztuczna inteligencja oparta na regułach:\\nWykorzystuje zestawy reguł logicznych do\\npodejmowania decyzji. Systemy te są zazwyczaj\\nużywane w problemach, gdzie istnieje jasny\\nzestaw reguł i zależności.\\nSztuczna inteligencja interakcyjna: \\nSkupiona \\nna \\nzdolności \\ndo \\ninterakcji \\nz\\nużytkownikami w sposób, który przypomina\\nludzką komunikację. Obejmuje to chatboty,\\nasystentów \\nwirtualnych \\ni \\nsystemy\\nrozpoznawania mowy.\\nTe rodzaje sztucznej inteligencji różnią się w\\nswoich \\npodejściach, \\nzastosowaniach \\ni\\nzdolnościach, \\nco \\numożliwia \\ndostosowanie\\ntechnologii do różnych problemów i dziedzin.\\n'}}, {'id': 461834675364823499, 'distance': 35.05402755737305, 'entity': {'text': 'Sztuczna superinteligencja (ASI)\\nSystem \\nkomputerowy, \\nktóry \\nosiągnąłby\\nsztuczną superinteligencję, miałby zdolność\\nprzewyższania ludzi niemal w każdej dziedzinie,\\nw \\ntym \\nkreatywności \\nnaukowej, \\nogólnej\\nmądrości i umiejętnościach społecznych.\\nRodzaje sztucznej\\ninteligencji\\n1 1\\nWąskie sztuczne inteligencje (wąskie AI)\\nSztuczna, \\nwąska \\ninteligencja, \\nniekiedy\\nnazywana „słabą sztuczną inteligencją” odnosi\\nsię do zdolności systemu komputerowego do\\nwykonywania wąsko zdefiniowanych zadań\\nlepiej niż człowiek.\\nWąska \\nsztuczna \\ninteligencja \\nto \\nnajwyższy\\npoziom rozwoju sztucznej inteligencji, jaki\\nludzkość osiągnęła do tej pory i każdy przykład\\nsztucznej inteligencji, który możemy zobaczyć\\nw rzeczywistym świecie — w tym pojazdy\\nautonomiczne i osobiści asystenci cyfrowi —\\nnależy do tej kategorii. Dzieje się tak, ponieważ\\nnawet jeśli wydaje się, że sztuczna inteligencja\\nmyśli samodzielnie w czasie rzeczywistym, w\\nrzeczywistości \\nkoordynuje \\nkilka \\nwąskich\\nprocesów i podejmuje decyzje w ramach\\nwcześniej \\nustalonej \\nstruktury. \\n„Myślenie”\\nsztucznej \\ninteligencji \\nnie \\nobejmuje\\nświadomości ani emocji.\\n Sztuczna inteligencja ogólna (ogólna AI)\\nSztuczna \\ninteligencja \\nogólna \\n— \\nczasami\\nnazywana „silną sztuczną inteligencją” lub\\n„sztuczną inteligencją na poziomie ludzkim”—\\nodnosi \\nsię \\ndo \\nzdolności \\nsystemu\\nkomputerowego do przewyższania ludzi w\\njakimkolwiek zadaniu intelektualnym. To rodzaj\\nsztucznej inteligencji, który można zobaczyć w\\nfilmach, w których roboty mają świadome myśli\\ni działają z własnych pobudek.\\nTeoretycznie \\nsystem \\nkomputerowy, \\nktóry\\nosiągnął ogólną sztuczną inteligencję, byłby w\\nstanie rozwiązywać głęboko złożone problemy,\\nzastosować osąd w niepewnych sytuacjach i\\nwłączyć \\nwcześniejszą \\nwiedzę \\ndo \\nswojego\\nobecnego \\nrozumowania. \\nByłby \\nzdolny \\ndo\\nkreatywności i wyobraźni na równi z ludźmi i\\nmógłby wykonywać znacznie szerszy zakres\\nzadań, niż wąska sztuczna inteligencja.\\nŹródło: Canva\\n'}}, {'id': 461834675364823503, 'distance': 35.47592544555664, 'entity': {'text': 'Sztuczna inteligencja\\ngeneratywna\\n1 5\\nW ekonomii powszechnie stosuje się systemy\\nautomatycznie \\noceniające \\nm.in. \\nzdolność\\nkredytową, profil najlepszych klientów czy\\nplanujące kampanie reklamowe. Systemy te\\npoddawane są wcześniej automatycznemu\\nuczeniu na podstawie posiadanych danych (np.\\nklientów \\nbanku, \\nktórzy \\nregularnie \\nspłacali\\nkredyt i klientów, którzy mieli z tym problemy).\\nInteligentne \\ninterfejsy \\n– \\nstosowane \\ndo\\nzautomatyzowanego \\nzarządzania,\\nmonitorowania, raportowania oraz podjęcia\\nprób rozwiązywania potencjalnych problemów\\nw procesach technologicznych.\\nPrognozowanie i wykrywanie oszustw – przy\\nużyciu \\nm.in. \\nregresji \\nlogistycznej, \\nsystemy\\nanalizują zbiory danych w celu wychwytywania\\nnp. podejrzanych transakcji finansowych.\\nAnaliza wideo w czasie rzeczywistym – znajduje\\nzastosowanie m.in. w systemach monitoringu,\\nsystemach \\nzarządzania \\nruchem \\nsamo-\\nchodowym / pieszym i prognozowaniu takiego\\nruchu.\\nPrzykłady sztucznej inteligencji\\ngeneratywnej obejmują:\\nGeneratywne modele tekstowe:\\nGPT \\n(Generative \\nPre-trained \\nTransformer):\\nModele tego rodzaju, takie jak GPT-3, są w\\nstanie generować nowe teksty na podstawie\\npodanych im fragmentów lub tematów. Mogą\\npisać artykuły, opowiadania, a nawet kody\\nprogramów komputerowych.\\nGeneratywne modele obrazów:\\nGenerative Adversarial Networks (GANs): To\\nrodzaj modelu, w którym dwie sieci neuronowe,\\ngenerator i dyskryminator, konkurują ze sobą.\\nGenerator tworzy nowe obrazy, podczas gdy\\ndyskryminator ocenia, czy są one autentyczne\\nczy wygenerowane. To podejście doprowadza\\ndo stworzenia bardzo realistycznych obrazów,\\nktóre mogą być trudne do odróżnienia od\\nfotografii.\\nGeneratywne modele dźwięków:\\nWaveGAN: Modele tego typu są zdolne do\\ngenerowania realistycznych dźwięków, takich\\njak mowa, muzyka czy efekty dźwiękowe.\\nWaveGAN jest przykładem algorytmu, który\\nmoże tworzyć nowe próbki dźwiękowe.\\nGeneratywne modele wideo:\\nDeepfake: Choć deepfake może być używany w\\nróżnych kontekstach, w tym również złośliwych,\\njest \\nto \\ntechnologia \\ngeneratywna, \\nktóra\\nwykorzystuje głębokie uczenie maszynowe do\\nzastępowania twarzy jednej osoby na nagraniu\\nwideo twarzą innej. Może być używana do\\ntworzenia realistycznych, ale fałszywych filmów.\\nSztuczna inteligencja\\ngeneratywna \\nSztuczna \\ninteligencja \\ngeneratywna \\n(ang.\\nGenerative Artificial Intelligence) to obszar\\nsztucznej inteligencji, który koncentruje się na\\ntworzeniu nowych danych, obrazów, dźwięków\\nlub innych treści, które nie istniały wcześniej. Te\\nsystemy są zdolne do generowania nowych,\\nautentycznych \\nelementów \\nna \\npodstawie\\nwzorców \\ni \\ninformacji, \\nktóre \\nzostały \\nim\\ndostarczone w trakcie treningu. Generatywne\\nmodele AI mają zdolność tworzenia treści, które\\nmogą \\nbyć \\ntrudno \\nodróżnione \\nod \\ntych\\nstworzonych przez ludzi.\\n'}}]\n"
     ]
    }
   ],
   "source": [
    "# search\n",
    "def search(milvus_embedding_model, query, milvus_client=milvus_client, limit: int = 5):\n",
    "    embedded_query = milvus_embedding_model.encode(query).tolist()\n",
    "    result = milvus_client.search(\n",
    "        collection_name=\"rag_texts_and_embeddings\",\n",
    "        data=[embedded_query],\n",
    "        limit=limit,\n",
    "        search_params={\"metric_type\": \"L2\"},\n",
    "        output_fields=[\"text\"],\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "result = search(milvius_embedding_model, query=\"Czym jest sztuczna inteligencja\")\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb1adb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format search output to put it into prompt as a context\n",
    "def format_search_output(search_results) -> str:\n",
    "    formatted_results = []\n",
    "    for i, hit in enumerate(search_results[0]):\n",
    "        text = hit.entity.get(\"text\")\n",
    "        formatted_results.append(f\"Document: {i + 1}\\nContent: {text}\")\n",
    "    return \"\\n---\\n\".join(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84cada16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM configuration\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=GEMINI_KEY)\n",
    "\n",
    "MODEL_ID = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "def generate_response(model_id, llm_client, prompt: str):\n",
    "    try:\n",
    "        # Send request to Gemini 2.0 Flash API and get the response\n",
    "        response = llm_client.models.generate_content(\n",
    "            model=model_id,\n",
    "            contents=prompt,\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29d8f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context: str, query: str) -> str:\n",
    "    # I guess prompt can be optimized more but for now it should work fine\n",
    "    # E.g Anthropic models use xml tags for prompt templates, have to check out\n",
    "    # what is best practice for Gemini models\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        f\"\"\"\n",
    "    INSTRUKCJE:\n",
    "    1. Jesteś ekspertem ds. sztucznej inteligencji.\n",
    "    2. Przeanalizuj poniższy \"KONTEKST\".\n",
    "    3. Odpowiedz na \"PYTANIE\" bazując *wyłącznie* na informacjach zawartych w \"KONTEKŚCIE\".\n",
    "    4. Jeśli \"KONTEKST\" nie zawiera informacji potrzebnych do odpowiedzi, napisz: \"Nie posiadam wystarczających informacji w podanym kontekście, aby odpowiedzieć na to pytanie.\"\n",
    "    5. Nie dodawaj żadnych informacji spoza \"KONTEKSTU\" ani nie wymyślaj odpowiedzi.\n",
    "    6. Odpowiedz w języku polskim.\n",
    "\n",
    "    KONTEKST:\n",
    "    ---\n",
    "    {context}\n",
    "    ---\n",
    "\n",
    "    PYTANIE:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "    )\n",
    "    return prompt.format(context=context, query=query)\n",
    "\n",
    "\n",
    "def rag(\n",
    "    llm_model, llm_client, embedding_model, query: str, milvus_client, top_k: int = 5\n",
    ") -> str:\n",
    "    search_results = search(\n",
    "        embedding_model, query=query, milvus_client=milvus_client, limit=top_k\n",
    "    )\n",
    "    formatted_context = format_search_output(search_results)\n",
    "    prompt = build_prompt(formatted_context, query)\n",
    "    response = generate_response(llm_model, llm_client, prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "beade943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sztuczna inteligencja (AI) to obszar informatyki, który skupia się na tworzeniu programów komputerowych zdolnych do wykonywania zadań, które wymagają ludzkiej inteligencji. Te zadania obejmują rozpoznawanie wzorców, rozumienie języka naturalnego, podejmowanie decyzji, uczenie się, planowanie i wiele innych. Głównym celem AI jest stworzenie systemów, które są zdolne do myślenia i podejmowania decyzji na sposób przypominający ludzki. W języku potocznym sztuczna inteligencja to coś (program, maszyna) symulujące inteligencję naturalną, ludzką.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Czym jest sztuczna inteligencja\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf046169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uczenie głębokie to zaawansowany rodzaj uczenia maszynowego, wykorzystujący sieci algorytmów inspirowanych strukturą mózgu, zwane sieciami neuronowymi. Głęboka sieć neuronowa ma zagnieżdżone węzły neuronowe, a każde pytanie, na które odpowiada, prowadzi do zestawu powiązanych pytań. Uczenie głębokie zazwyczaj wymaga dużego zestawu danych do treningu. Zestawy treningowe do uczenia głębokiego składają się czasami z milionów punktów danych. Po wytrenowaniu głębokiej sieci neuronowej na tych dużych zestawach danych może ona lepiej poradzić sobie z niejednoznacznościami niż sieć płytka. To sprawia, że ten mechanizm jest przydatny w aplikacjach takich jak rozpoznawanie obrazu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Co to deep learning i jakie są jego zastosowania?\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d98da7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na podstawie podanych dokumentów, mogę stwierdzić, że Transformer jest generatywnym modelem tekstowym, który jest w stanie generować nowe teksty na podstawie podanych fragmentów lub tematów. Modele tego rodzaju (np. GPT-3) mogą pisać artykuły, opowiadania, a nawet kody programów komputerowych. Nie posiadam informacji na temat tego, jak dokładnie działa ten model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Co to jest transformer i jak działa?\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a230087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bazując na dostarczonych informacjach, narzędzia do generowania obrazów za pomocą AI to:\n",
      "\n",
      "*   Pix2Pix\n",
      "*   Midjourney (MJ)\n",
      "*   Leonardo AI\n",
      "*   DALL·E 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Jakie są narzędzia do generacji obrazów za pomocą AI?\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5250995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybrane narzędzia SI do generowania wideo: Adobe Character Animator, Animaker, Castmagic, Colourlab.Ai, CupCat, Murf.ai, RunwayML, Stable Audio, Simplified, Suno IA, Synthesia, Veed.io, Videoleap, Visla, 10Levelup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Jakie są narzędzia do generacji wideo za pomocą AI?\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "206f1ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie posiadam wystarczających informacji w podanym kontekście, aby odpowiedzieć na to pytanie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = rag(\n",
    "    llm_model=MODEL_ID,\n",
    "    llm_client=gemini_client,\n",
    "    embedding_model=milvius_embedding_model,\n",
    "    query=\"Kim jest Leo Messi?\",\n",
    "    milvus_client=milvus_client,\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
